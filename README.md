# Vendor Performance Analysis

An end-to-end data analysis solution to help organizations measure and optimize vendor performance. By integrating supply chain data with statistical modeling, we identified key drivers of profitability and inventory efficiency.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/                   # Raw datasets created in MySQL Workbench
â”œâ”€â”€ IngestionFiles/         # Data ingestion and DB automation scripts
â”‚   â”œâ”€â”€ Ingestion.ipynb     # DB loading tests
â”‚   â””â”€â”€ ingestion_db.py     # Production ingestion script
â”œâ”€â”€ EDAFiles/               # SQL transformations and logic
â”‚   â”œâ”€â”€ Exploratory Data Analysis.ipynb
â”‚   â””â”€â”€ get_vendor_summary.py    # CTE-based data merging
â”œâ”€â”€ VPA/                    # Statistical analysis & hypothesis testing
â”‚   â””â”€â”€ Vendor Performance Analysis.ipynb
â”œâ”€â”€ FinalDataframe/         # Production-ready CSV
â”‚   â””â”€â”€ my_dataframe.csv   # The "Single Source of Truth"
â”œâ”€â”€ ProjectDashboard/       # Interactive web frontend visualization
â”‚   â”œâ”€â”€ index.html          # Secure login page
â”‚   â”œâ”€â”€ dashboard.html      # Main metrics view
â”‚   â”œâ”€â”€ style.css           # Custom UI styling
â”‚   â”œâ”€â”€ script.js           # Modal logic and auth
â”‚   â””â”€â”€ images/             # Visual plot assets (PNGs)
â”œâ”€â”€ logs/                   # System execution logs
â””â”€â”€ inventory.db            # Final SQLite database
```

---

## ğŸ› ï¸ Step 1: Data Creation & Ingestion

The project began by designing a relational database schema representing a retail supply chain.

- **Database Design:** Created 6 core tables (Inventory, Purchases, Sales, Invoices) using MySQL Workbench.
- **Automated Pipeline:** Developed a Python script (`ingestion_db.py`) to automate the migration of raw CSVs into a local SQLite database (`inventory.db`), including automated logging for performance monitoring.

---

## ğŸ“Š Step 2: Business Logic & Data Transformation

In the `EDAFiles/` phase, we moved beyond raw data to create high-level business entities.

- **SQL CTEs:** Used Common Table Expressions in Python to join disparate tables, calculating Lead Times, Freight Costs, and Sales-to-Purchase ratios at the vendor level.
- **Feature Engineering:** Calculated critical KPIs like Gross Profit, Profit Margin, and Stock Turnover to identify vendor health.

---

## ğŸ“ˆ Step 3: Statistical Analysis & Hypothesis Testing

The `VPA/` phase involved deep-dive research to find actionable patterns.

- **T-Tests & Confidence Intervals:** Compared profit margins between top and low-performing vendors. Top vendors operate at a statistically significant higher margin (~97%), which is not due to random chance.
- **Correlation Analysis:** Used heatmaps to identify the link (0.96) between sales volume and logistics overhead.
- **Outlier Detection:** Used boxplots to identify "Slow-Moving" products with a Stock Turnover < 1.

---

## ğŸŒ Step 4: Interactive Web Dashboard

The final output is a responsive Business Intelligence Dashboard that allows stakeholders to explore the findings.

- **Frontend Tech:** Built with HTML5, CSS3, and Vanilla JavaScript.
- **Secure Access:** Features a login gateway to protect sensitive vendor data.
- **Visual Insights:** A card-based layout where users can interact with modals to see detailed statistical plots and actionable business intelligence.

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.x
- Libraries: `pandas`, `sqlalchemy`, `matplotlib`, `seaborn`, `scipy`

### Running the Analysis

```bash
# Ingest data
python IngestionFiles/ingestion_db.py

# Generate vendor summaries
python EDAFiles/get_vendor_summary.py
```

### Launching the Dashboard

1. Open the `/ProjectDashboard` folder
2. Launch `index.html` using Live Server in VS Code
3. Login with the credentials below:

| Field    | Value      |
|----------|------------|
| Username | `admin`    |
| Password | `password` |

---

## ğŸ‘¥ Contributors

- Uddipan Roy
- Nikita Das
- Bastabika Das